{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDQUmLtbd0D3"
   },
   "source": [
    "# BERT (Bidirectional Encoder Representations from Transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T14:26:04.761561Z",
     "start_time": "2024-05-17T14:25:47.021547Z"
    },
    "id": "LLVomSZqMCBD"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T20:05:53.625779Z",
     "start_time": "2024-10-18T20:05:53.588178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\epuerta\\\\OneDrive - Universidad Tecnológica de Bolívar\\\\Apps\\\\AppsISCO\\\\InteligenciaArtificial-ISCO-A06A\\\\laboratories\\\\data\\\\'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "PATH = os.getcwd()\n",
    "DIR_DATA = PATH + '{0}data{0}'.format(os.sep)\n",
    "sys.path.append(PATH) if PATH not in list(sys.path) else None\n",
    "DIR_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Descargar recursos necesarios para el tokenizador de oraciones de NLTK\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\epuerta\\\\OneDrive - Universidad Tecnológica de Bolívar\\\\Apps\\\\AppsISCO\\\\InteligenciaArtificial-ISCO-A06A\\\\laboratories\\\\data\\\\AboutMe.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = DIR_DATA + 'AboutMe.txt'\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edwin Puertas is an AI Software Architect and NLP Researcher. Currently, I am an Associate Professor at the Universidad TecnolÃ³gica de BolÃ­var, and I simultaneously serve as a bridge between academia and industry in projects related to AI. My work focuses on developing innovative AI solutions that bridge the gap between theoretical research and practical applications. With over 19 years of experience in academia, I have taught courses in Artificial Intelligence, Natural Language Processing, Big Data, and Software Engineering, fostering an environment of collaborative learning and research excellence.\n",
      "\n",
      "As an AI Software Architect, I lead projects involving the design and implementation of scalable AI systems, applying advanced machine learning techniques to solve complex problems across various industries. My research in NLP explores the intricacies of human language, aiming to enhance natural language understanding and develop applications that improve human-computer interaction.\n",
      "\n",
      "I have been involved in numerous collaborative initiatives that connect academic research with industry needs, facilitating the transfer of knowledge and technology to create impactful solutions. My commitment to innovation and excellence has been recognized through various grants and awards, supporting projects that advance the field of AI. As a Senior Member of the IEEE, I actively participate in international conferences and workshops, contributing to the global discourse on AI advancements and best practices.\n"
     ]
    }
   ],
   "source": [
    "# Abre el archivo en modo lectura\n",
    "with open(filename, 'r') as archivo:\n",
    "    contexto = archivo.read()\n",
    "\n",
    "# Muestra el contenido del archivo\n",
    "print(contexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:22:39.513459Z",
     "start_time": "2024-10-18T13:22:37.706419Z"
    },
    "id": "p4gGmgPMQsZh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "the_model = 'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'\n",
    "tokenizer = AutoTokenizer.from_pretrained(the_model, do_lower_case=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(the_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jokmyxjASRH6",
    "outputId": "1cd9bf04-d510-45dd-9e51-d14f939c3237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForQuestionAnswering(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración 1:\n",
      "Texto original: ¿Cuantos años de experiencia tiene?\n",
      "Tokens de BERT: ['[CLS]', '¿', 'Cuanto', '##s', 'años', 'de', 'experiencia', 'tiene', '?', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 2:\n",
      "Texto original: Edwin Puertas is an AI Software Architect and NLP Researcher.\n",
      "Tokens de BERT: ['[CLS]', '[UNK]', 'Puerta', '##s', 'is', 'an', 'AI', '[UNK]', 'Archi', '##tec', '##t', 'and', 'NL', '##P', 'Research', '##er', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 3:\n",
      "Texto original: Currently, I am an Associate Professor at the Universidad TecnolÃ³gica de BolÃ­var, and I simultaneously serve as a bridge between academia and industry in projects related to AI.\n",
      "Tokens de BERT: ['[CLS]', 'Cur', '##ren', '##t', '##ly', ',', 'I', 'am', 'an', 'Associa', '##te', 'Profes', '##sor', 'at', 'the', 'Universidad', '[UNK]', 'de', '[UNK]', ',', 'and', 'I', 'simul', '##tan', '##eo', '##us', '##ly', 'serv', '##e', 'as', 'a', 'bri', '##dge', '[UNK]', 'academia', 'and', 'indust', '##ry', 'in', 'pro', '##ject', '##s', 'rela', '##ted', 'to', 'AI', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 4:\n",
      "Texto original: My work focuses on developing innovative AI solutions that bridge the gap between theoretical research and practical applications.\n",
      "Tokens de BERT: ['[CLS]', 'My', '[UNK]', 'fo', '##cus', '##es', 'on', 'dev', '##elo', '##pin', '##g', 'innov', '##ati', '##ve', 'AI', 'solu', '##tions', 'that', 'bri', '##dge', 'the', 'ga', '##p', '[UNK]', 'the', '##ore', '##tica', '##l', 'rese', '##ar', '##ch', 'and', 'practica', '##l', 'ap', '##plica', '##tions', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 5:\n",
      "Texto original: With over 19 years of experience in academia, I have taught courses in Artificial Intelligence, Natural Language Processing, Big Data, and Software Engineering, fostering an environment of collaborative learning and research excellence.\n",
      "Tokens de BERT: ['[CLS]', 'W', '##ith', 'over', '19', 'ye', '##ars', 'of', 'exper', '##ien', '##ce', 'in', 'academia', ',', 'I', 'have', 'ta', '##ugh', '##t', 'co', '##urs', '##es', 'in', 'Arti', '##ficial', 'Inte', '##lli', '##gen', '##ce', ',', 'Natural', 'Lang', '##ua', '##ge', 'Proces', '##sing', ',', 'Big', 'Data', ',', 'and', '[UNK]', 'Eng', '##ine', '##ering', ',', 'fos', '##teri', '##ng', 'an', 'envi', '##ron', '##ment', 'of', 'col', '##lab', '##ora', '##tive', 'lea', '##r', '##ning', 'and', 'rese', '##ar', '##ch', 'excel', '##len', '##ce', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 6:\n",
      "Texto original: As an AI Software Architect, I lead projects involving the design and implementation of scalable AI systems, applying advanced machine learning techniques to solve complex problems across various industries.\n",
      "Tokens de BERT: ['[CLS]', 'As', 'an', 'AI', '[UNK]', 'Archi', '##tec', '##t', ',', 'I', 'lea', '##d', 'pro', '##ject', '##s', 'invol', '##ving', 'the', 'design', 'and', 'implement', '##ation', 'of', 's', '##cala', '##ble', 'AI', 's', '##ystem', '##s', ',', 'ap', '##pl', '##yi', '##ng', 'ad', '##van', '##ced', 'mach', '##ine', 'lea', '##r', '##ning', 'tech', '##ni', '##ques', 'to', 'sol', '##ve', 'comple', '##x', 'proble', '##ms', 'ac', '##ross', 'vari', '##ou', '##s', 'industri', '##es', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 7:\n",
      "Texto original: My research in NLP explores the intricacies of human language, aiming to enhance natural language understanding and develop applications that improve human-computer interaction.\n",
      "Tokens de BERT: ['[CLS]', 'My', 'rese', '##ar', '##ch', 'in', 'NL', '##P', 'explor', '##es', 'the', 'intri', '##ca', '##cies', 'of', 'human', 'lan', '##gua', '##ge', ',', 'a', '##imi', '##ng', 'to', 'en', '##han', '##ce', 'natural', 'lan', '##gua', '##ge', 'under', '##stan', '##ding', 'and', 'dev', '##elo', '##p', 'ap', '##plica', '##tions', 'that', 'impro', '##ve', 'human', '-', 'comput', '##er', 'interac', '##tion', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 8:\n",
      "Texto original: I have been involved in numerous collaborative initiatives that connect academic research with industry needs, facilitating the transfer of knowledge and technology to create impactful solutions.\n",
      "Tokens de BERT: ['[CLS]', 'I', 'have', 'be', '##en', 'invol', '##ved', 'in', 'numero', '##us', 'col', '##lab', '##ora', '##tive', 'in', '##iti', '##ati', '##ves', 'that', 'con', '##ne', '##ct', 'aca', '##demi', '##c', 'rese', '##ar', '##ch', 'w', '##ith', 'indust', '##ry', 'ne', '##eds', ',', 'facilita', '##ting', 'the', 'transfer', 'of', '[UNK]', 'and', 'tech', '##nol', '##o', '##gy', 'to', 'crea', '##te', 'impac', '##t', '##ful', 'solu', '##tions', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 9:\n",
      "Texto original: My commitment to innovation and excellence has been recognized through various grants and awards, supporting projects that advance the field of AI.\n",
      "Tokens de BERT: ['[CLS]', 'My', 'com', '##mit', '##ment', 'to', 'innov', '##ation', 'and', 'excel', '##len', '##ce', 'has', 'be', '##en', 'reco', '##gni', '##ze', '##d', 'th', '##ro', '##ugh', 'vari', '##ou', '##s', 'gran', '##ts', 'and', '[UNK]', ',', 'sup', '##port', '##ing', 'pro', '##ject', '##s', 'that', 'ad', '##van', '##ce', 'the', 'fiel', '##d', 'of', 'AI', '.', '[SEP]']\n",
      "--------------------------------------------------\n",
      "Oración 10:\n",
      "Texto original: As a Senior Member of the IEEE, I actively participate in international conferences and workshops, contributing to the global discourse on AI advancements and best practices.\n",
      "Tokens de BERT: ['[CLS]', 'As', 'a', 'Sen', '##ior', 'Mem', '##ber', 'of', 'the', 'IE', '##E', '##E', ',', 'I', 'activ', '##ely', 'participa', '##te', 'in', 'interna', '##tional', 'confer', '##ence', '##s', 'and', '[UNK]', ',', 'contrib', '##uti', '##ng', 'to', 'the', 'global', 'disco', '##urs', '##e', 'on', 'AI', 'ad', '##van', '##ce', '##ments', 'and', 'bes', '##t', 'practic', '##es', '.', '[SEP]']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"¿Cuantos años de experiencia tiene?\"\n",
    "\n",
    "#Tokenizar el contexto por oraciones usando nltk\n",
    "oraciones_contexto = nltk.sent_tokenize(contexto)\n",
    "\n",
    "# Añadir la pregunta como la primera oración\n",
    "oraciones = [pregunta] + oraciones_contexto\n",
    "\n",
    "# Procesar cada oración por separado\n",
    "for idx, oracion in enumerate(oraciones):\n",
    "    # Codificar la oración sola, utilizando encode_plus para cada oración\n",
    "    encode = tokenizer.encode_plus(oracion, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    \n",
    "    # Obtener los input_ids y convertirlos en tokens\n",
    "    input_ids = encode[\"input_ids\"]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    # Mostrar la oración original y sus tokens\n",
    "    print(f\"Oración {idx + 1}:\")\n",
    "    print(f\"Texto original: {oracion}\")\n",
    "    print(f\"Tokens de BERT: {tokens}\")\n",
    "    print(\"-\" * 50)  # Separador entre oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.24410812556743622, 'start': 378, 'end': 385, 'answer': 'over 19'}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo pregunta respuesta\n",
    "nlp = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "salida = nlp({\"question\": pregunta, \"context\":contexto})\n",
    "print(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hawFgMcHZDpe"
   },
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "\n",
    "def pregunta_respuesta(model, contexto, nlp):\n",
    "\n",
    "  # Imprimir contexto\n",
    "  print('Contexto:')\n",
    "  print('-----------------')\n",
    "  print('\\n'.join(wrap(contexto)))\n",
    "\n",
    "  # Loop preguntas-respuestas:\n",
    "  continuar = True\n",
    "  while continuar:\n",
    "    print('\\nPregunta:')\n",
    "    print('-----------------')\n",
    "    pregunta = str(input())\n",
    "\n",
    "    continuar = pregunta!=''\n",
    "\n",
    "    if continuar:\n",
    "      salida = nlp({'question':pregunta, 'context':contexto})\n",
    "      print('\\nRespuesta:')\n",
    "      print('-----------------')\n",
    "      print(salida['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ac7YqpvHd5td"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto:\n",
      "-----------------\n",
      "Edwin Puertas is an AI Software Architect and NLP Researcher.\n",
      "Currently, I am an Associate Professor at the Universidad TecnolÃ³gica\n",
      "de BolÃ­var, and I simultaneously serve as a bridge between academia\n",
      "and industry in projects related to AI. My work focuses on developing\n",
      "innovative AI solutions that bridge the gap between theoretical\n",
      "research and practical applications. With over 19 years of experience\n",
      "in academia, I have taught courses in Artificial Intelligence, Natural\n",
      "Language Processing, Big Data, and Software Engineering, fostering an\n",
      "environment of collaborative learning and research excellence.  As an\n",
      "AI Software Architect, I lead projects involving the design and\n",
      "implementation of scalable AI systems, applying advanced machine\n",
      "learning techniques to solve complex problems across various\n",
      "industries. My research in NLP explores the intricacies of human\n",
      "language, aiming to enhance natural language understanding and develop\n",
      "applications that improve human-computer interaction.  I have been\n",
      "involved in numerous collaborative initiatives that connect academic\n",
      "research with industry needs, facilitating the transfer of knowledge\n",
      "and technology to create impactful solutions. My commitment to\n",
      "innovation and excellence has been recognized through various grants\n",
      "and awards, supporting projects that advance the field of AI. As a\n",
      "Senior Member of the IEEE, I actively participate in international\n",
      "conferences and workshops, contributing to the global discourse on AI\n",
      "advancements and best practices.\n",
      "\n",
      "Pregunta:\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ¿donde estudio?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta:\n",
      "-----------------\n",
      "Universidad TecnolÃ³gica de BolÃ­var\n",
      "\n",
      "Pregunta:\n",
      "-----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pregunta_respuesta(model, contexto, nlp)\n",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m, in \u001b[0;36mpregunta_respuesta\u001b[1;34m(model, contexto, nlp)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPregunta:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m pregunta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28minput\u001b[39m())\n\u001b[0;32m     17\u001b[0m continuar \u001b[38;5;241m=\u001b[39m pregunta\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m continuar:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "pregunta_respuesta(model, contexto, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJdZuTdTjFff",
    "outputId": "ac8ac5a5-a86e-4031-fb47-eed4a314f377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto:\n",
      "-----------------\n",
      "Avengers: Endgame (Vengadores: Endgame en España)2​ es una película de\n",
      "superhéroes estadounidense de 2019 basada en el equipo de superhéroes\n",
      "Los Vengadores de Marvel Comics. Producida por Marvel Studios y\n",
      "distribuida por Walt Disney Studios Motion Pictures, es la secuela\n",
      "directa de Avengers: Infinity War (2018) y la película número 22 del\n",
      "Universo cinematográfico de Marvel (UCM), y hasta la fecha la más\n",
      "larga. Dirigida por Anthony y Joe Russo y escrita por Christopher\n",
      "Markus y Stephen McFeely, la película cuenta con un reparto coral que\n",
      "incluye a Robert Downey Jr., Chris Evans, Mark Ruffalo, Chris\n",
      "Hemsworth, Scarlett Johansson, Jeremy Renner, Don Cheadle, Paul Rudd,\n",
      "Brie Larson, Karen Gillan, Danai Gurira, Benedict Wong, Jon Favreau,\n",
      "Bradley Cooper, Gwyneth Paltrow y Josh Brolin. En la película, los\n",
      "miembros supervivientes de Los Vengadores y sus aliados intentan\n",
      "revertir el daño causado por Thanos en Infinity War.\n",
      "\n",
      "Pregunta:\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ¿quien Chris evans?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta:\n",
      "-----------------\n",
      "de Marvel (UCM), y hasta la\n",
      "\n",
      "Pregunta:\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "contexto = \"Avengers: Endgame (Vengadores: Endgame en España)2​ es una película de superhéroes estadounidense de 2019 basada en el equipo de superhéroes Los Vengadores de Marvel Comics. Producida por Marvel Studios y distribuida por Walt Disney Studios Motion Pictures, es la secuela directa de Avengers: Infinity War (2018) y la película número 22 del Universo cinematográfico de Marvel (UCM), y hasta la fecha la más larga. Dirigida por Anthony y Joe Russo y escrita por Christopher Markus y Stephen McFeely, la película cuenta con un reparto coral que incluye a Robert Downey Jr., Chris Evans, Mark Ruffalo, Chris Hemsworth, Scarlett Johansson, Jeremy Renner, Don Cheadle, Paul Rudd, Brie Larson, Karen Gillan, Danai Gurira, Benedict Wong, Jon Favreau, Bradley Cooper, Gwyneth Paltrow y Josh Brolin. En la película, los miembros supervivientes de Los Vengadores y sus aliados intentan revertir el daño causado por Thanos en Infinity War.\"\n",
    "pregunta_respuesta(model, contexto, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
